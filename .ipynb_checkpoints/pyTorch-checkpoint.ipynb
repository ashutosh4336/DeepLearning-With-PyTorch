{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENV Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning With PyTorch\n"
     ]
    }
   ],
   "source": [
    "# ENV Setup\n",
    "# For Dark Theme nad to Rest to Default\n",
    "# !pip install jupyterthemes\n",
    "\n",
    "# from jupyterthemes import get_themes\n",
    "# from jupyterthemes.stylefx import set_nb_theme\n",
    "\n",
    "# set_nb_theme('onedork')\n",
    "\n",
    "# !jt -r\n",
    "\n",
    "print('Deep Learning With PyTorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] NOTE: Jovian is currently in beta, so if you face any issues, \n",
      "               please report them here: https://github.com/JovianML/jovian-py/issues\u001b[0m\n",
      "[jovian] Fetching aakashns/01-pytorch-basics ..\u001b[0m\n",
      "[jovian] Downloading files..\u001b[0m\n",
      "[jovian] \u001b[32mCloned successfully to '01-pytorch-basics'\u001b[0m\n",
      "\u001b[33m\u001b[4m\n",
      "Next steps:\u001b[0m\u001b[1m\n",
      "  $ cd 01-pytorch-basics\n",
      "  $ jovian install\n",
      "  $ conda activate <env_name>\n",
      "  $ jupyter notebook\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "Replace <env_name> with the name of your environment (without the '<' & '>')\n",
      "Jovian uses Anaconda ( https://conda.io/ ) under the hood,\n",
      "so please make sure you have it installed and added to path.\n",
      "* If you face issues with `jovian install`, try `conda env update`.\n",
      "* If you face issues with `conda activate`, try `source activate <env_name>`\n",
      "  or `activate <env_name>` to activate the virtual environment.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install jovian --upgrade\n",
    "\n",
    "# !jovian clone aakashns/01-pytorch-basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we complete our discussion of tensors and gradients in PyTorch, and we're ready to move on to the next topic: *Linear regression*.\n",
    "\n",
    "## Credits\n",
    "\n",
    "The material in this series is heavily inspired by the following resources:\n",
    "\n",
    "1. [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi: \n",
    "\n",
    "2. [FastAI development notebooks](https://github.com/fastai/fastai_docs/tree/master/dev_nb) by Jeremy Howard: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter One [  PyTorch Basics  ]\n",
    "### Tensor and Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls\n",
    "# !pwd\n",
    "# !cd 01-pytorch-basics/\n",
    "\n",
    "# !pip install torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor(4.)\n",
    "# print(t1)\n",
    "# print(type(t1))\n",
    "# t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "t2 = torch.tensor([1.,2,3,4])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [10., 21.],\n",
       "        [65., 56.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "t3 = torch.tensor([[1.,2],[10,21],[65,56]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11., 12., 13.],\n",
       "         [14., 15., 16.]],\n",
       "\n",
       "        [[17., 18., 19.],\n",
       "         [20., 21., 22.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-Dimension\n",
    "t4 = torch.tensor([\n",
    "    [[11,12,13],\n",
    "    [14,15,16]],\n",
    "    [[17,18,19],\n",
    "    [20.,21,22]]\n",
    "])\n",
    "# Have to supply same number of element\n",
    "# expected sequence of length 3 at dim 2 (got 4)\n",
    "\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor can have any Number of Dimension, and Different lengths along each Dimension. We can inspect the length along each dimension using __.shape__ property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations and Gradients\n",
    "We can combine tensors with the usual arithmetic operations. Lets look an Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensor\n",
    "x = torch.tensor(2.)\n",
    "w = torch.tensor(5., requires_grad=True)\n",
    "b = torch.tensor(9., requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've Created 3 Tensors ```x```,```w``` and ```b```, all numbers. w and b have an additional parameter __requires_grad__ set to __True__. We'll see that what it does in just a moment.\n",
    "\n",
    "Let's create a new Tensor ```y``` by combining these Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = w * x + b\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, ```y``` is a tensor with the value ```5 * 2 + 9 = 19```. What makes __PyTorch__ special is that we can automatically compute the derivative of ```y``` w.r.t. the tensors that have ```requires_grad``` set to ```True``` i.e. ```w``` and ```b```. To compute the derivatives, we can call the ```.backward``` method on our result ```y```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Derivative\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Derivative of ```y``` w.r.t the input tensors are stored in the ```.grad``` property of the respective Tesnor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(2.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display Gradients\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `dy/dw` has the same value as `x` i.e. `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None`, because `x` doesn't have `requires_grad` set to `True`. \n",
    "\n",
    "The \"grad\" in `w.grad` stands for gradient, which is another term for derivative, used mainly when dealing with matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability with ```Numpy```\n",
    "\n",
    "[Numpy](http://www.numpy.org/) is a popular open source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays, and has a large ecosystem of supporting libraries:\n",
    "\n",
    "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
    "* [OpenCV](https://opencv.org/) for image and video processing\n",
    "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
    "\n",
    "Instead of reinventing the wheel, PyTorch interoperates really well with Numpy to leverage its existing ecosystem of tools and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]] float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.array([[1,2], [3,4.]])\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can Convert the numpy array to a torch Tensor by ```torch.from_numpy()``` or ```torch.tensor()```\n",
    "\n",
    "In ```torch.from_numpy()``` it uses same space and Memory where as ```torch.tensor()``` create a copy of the data on Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert numpy array to torch tensor:\n",
    "y = torch.from_numpy(x)\n",
    "# y = torch.tensor(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, y.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can Convert a PyTorch tensor to Numpy array using the ```.numpy``` method of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.numpy()\n",
    "print(z)\n",
    "z.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Interoperability between PyTorch and Numpy is really important because most Datasets you'll  work with will likely to be read and processed as Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jovian\n",
    "# jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter - II [  Linear Regression  ]\n",
    "\n",
    "### Linear Regression and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with PyTorch\n",
    "\n",
    "In  this chapter we'll discuss one of the foundational  algorithms of machine learning in this post: *Linear regression*. We'll create a model that predicts crop yields for apples and oranges (*target variables*) by looking at the average temperature, rainfall and humidity (*input variables or features*) in a region. Here's the training data:\n",
    "\n",
    "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n",
    "\n",
    "In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
    "\n",
    "```\n",
    "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "```\n",
    "\n",
    "Visually, it means that the yield of apples is a linear or planar function of temperature, rainfall and humidity:\n",
    "\n",
    "![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)\n",
    "\n",
    "The *learning* part of linear regression is to figure out a set of weights `w11, w12,... w23, b1 & b2` by looking at the training data, to make accurate predictions for new data (i.e. to predict the yields for apples and oranges in a new region using the average temperature, rainfall and humidity). This is done by adjusting the weights slightly many times to make better predictions, using an optimization technique called *gradient descent*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "The training data can be represented using 2 matrices: `inputs` and `targets`, each with one row per observation, and one column per variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Data (temp, rainfall, humidity)\n",
    "inputs = np.array([\n",
    "                   [73,67,43],\n",
    "                   [91,88,64],\n",
    "                   [87,134,58],\n",
    "                   [102,43,37],\n",
    "                   [69,96,70]\n",
    "                  ], dtype='float32')\n",
    "\n",
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (Apple, Orange)\n",
    "targets = np.array([\n",
    "    [56,70],\n",
    "    [81,101],\n",
    "    [119,113],\n",
    "    [22,37],\n",
    "    [103,119]\n",
    "],dtype='float32')\n",
    "# targets.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've separated the input and target variables, because we'll operate on them separately. Also, we've created numpy arrays, because this is typically how you would work with training data: read some CSV files as numpy arrays, do some processing, and then convert them to PyTorch tensors as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0769ba300189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "inputs1 = torch.from_numpy(inputs)\n",
    "\n",
    "print(inputs1.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
